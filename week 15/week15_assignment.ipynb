{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Working with a database\n",
    "\n",
    "This week's assignment has a few basic steps.  First, we're going to pull some data down off the internet and store it into our MySQL database.  Make sure that you use your username as part of the table name as show in the examples so that you don't create a problem for other students.\n",
    "\n",
    "Then, we'll merge that with some data already in the database and calculate a few results.  When it comes to calculating the results, you can do so either with SQL or with Pandas operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 1: Setup your database connection and table name\n",
    "\n",
    "In the code below, change the value of the variable `MYTABLE` to use your own username rather that `'pboal'`\n",
    "\n",
    "You can then use `MYTABLE` in the rest of your code to reference that table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'slucor2022-instance-1.cgdcoitnku0k.us-east-1.rds.amazonaws.com'\n",
    "port = '3306'\n",
    "user = 'slucor2022'\n",
    "password = 'SLUcor2022'\n",
    "database = 'hds5210'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_engine('mysql+pymysql://' + \n",
    "                     user + ':' + \n",
    "                     password + '@' + \n",
    "                     host + '/' + \n",
    "                     database, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "myname = getpass.getuser().split('-')[1]\n",
    "myname\n",
    "MYTABLE=myname + '_data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q01-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(MYTABLE != 'pboal')\n",
    "assert(conn.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 2: Bring in outside data\n",
    "\n",
    "Grab the data from this URL and put it into a database table named with your `username_data`.\n",
    "\n",
    "https://opendata.arcgis.com/api/v3/datasets/ed0bc689bde246b18835c7529ba4efb4_0/downloads/data?format=csv&spatialRefId=4326\n",
    "\n",
    "By the end of your cell, the table should be created.  The tests are going to verify that the table exists and looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ehr_df = pd.read_csv(\"../EHR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_df.to_sql(MYTABLE, conn, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q02-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dxyz = pd.read_sql_query('SELECT * FROM ' + MYTABLE, conn)\n",
    "assert(dxyz.shape == (323,22))\n",
    "assert(list(dxyz.columns) == ['index', 'X', 'Y', 'OBJECTID', 'Provider_Name', 'NPI', 'CCN',\n",
    "       'Business_Street_Address', 'Business_City', 'Business_County',\n",
    "       'Business_ZIP_Code', 'Business_State_Territory', 'Payment_Year_Number',\n",
    "       'Program_Type', 'Medicaid_EP_Hospital_Type', 'total_payments',\n",
    "       'Last_Payment_Criteria', 'Recent_Disbursement_Amount', 'Latitude',\n",
    "       'Longitude', 'Last_Program_Year', 'Last_Payment_Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q03-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 3: Combine with other data in the database\n",
    "\n",
    "In the database, there is an existing table called `population`.  We want to merge the DHCS datafile loaded above with the population data available in this other database table  The tables can be merged on `MYTABLE`'s `Business_ZIP_Code` field and `population`'s `Zip` field.\n",
    "\n",
    "Note that not all `Zip_Codes` from your downloaded file have to be in the `population` table.  If they aren't, then I want you to eliminate the non-matching records.  That is, only keep the records that have a matching ZIP code in both sets of data.\n",
    "\n",
    "Answer the question:\n",
    "Which providers are located in the zipcode with the largest population?\n",
    "\n",
    "Put your answer in the form `answer = ['a', 'list', 'of', 'NPI', 'like', '1593042103]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.read_sql_query(\"\"\"\n",
    "  SELECT h.NPI\n",
    "  FROM \n",
    "    svelicheti_data h JOIN\n",
    "    population s ON h.Business_ZIP_Code = s.Zip\n",
    "  ORDER BY Population DESC\n",
    "  LIMIT 1\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = list(ans['NPI'])\n",
    "answer[0] = str(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q03-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == list)\n",
    "assert(answer == ['1194016923'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 4: Total by hospital type\n",
    "\n",
    "This is a multistep process:\n",
    "* From our downloaded data file, compute the `Total payments` per ZIP code and Medicaid EP Hospital Type.\n",
    "* Then merge that with the `population` data to compute a `Total payments` per person.\n",
    "* Then average that across all of the `Medicaid EP Hospital Types` to get an average per persona payment for these type of hospital.\n",
    "\n",
    "Your answer should be in structure of a data frame with at least two columns:\n",
    "* Medicaid_EP_Hospital_Type\n",
    "* Avg_Pay_per_Capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_tot_pay = pd.read_sql_query(\"\"\"\n",
    "    SELECT Business_ZIP_Code, Medicaid_EP_Hospital_Type, Sum(total_payments) as tot_payments\n",
    "  FROM \n",
    "    svelicheti_data\n",
    "  GROUP BY Business_ZIP_Code, Medicaid_EP_Hospital_Type\n",
    "\"\"\", conn)\n",
    "computed_tot_pay.to_sql('comp_tot_pay', conn, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_tot_pay = pd.read_sql_query(\"\"\"\n",
    "    SELECT Medicaid_EP_Hospital_Type, AVG(tot_payments/Population) as Avg_Pay_per_Capita\n",
    "  FROM \n",
    "    population JOIN\n",
    "    comp_tot_pay ON Zip = Business_ZIP_Code\n",
    "  GROUP BY Medicaid_EP_Hospital_Type\n",
    "\"\"\", conn)\n",
    "answer = computed_tot_pay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q04-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == pd.core.frame.DataFrame)\n",
    "assert(round(answer.query(\"Medicaid_EP_Hospital_Type == 'Acute Care Hospitals'\")['Avg_Pay_per_Capita'].sum(),3) == 106.583)\n",
    "assert(round(answer.query(\"Medicaid_EP_Hospital_Type == 'Children\\\\'s Hospitals'\")['Avg_Pay_per_Capita'].sum(),3) == 329.551)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using Pandas instead of SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_sql_query(\"\"\"SELECT * FROM population\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_tot_pay = pd.pivot_table(ehr_df, index = ['Business_ZIP_Code', 'Medicaid_EP_Hospital_Type'], values = 'total_payments', aggfunc = np.sum)\n",
    "computed_tot_pay = computed_tot_pay.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = computed_tot_pay.merge(population_df, how='inner', left_on = 'Business_ZIP_Code', right_on ='Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['tot_pay_per_person'] = merged_data['total_payments'] / merged_data['Population']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = merged_data.groupby(['Medicaid_EP_Hospital_Type'])['tot_pay_per_person'].agg(Avg_Pay_per_Capita = ('mean'))\n",
    "answer = answer.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(type(answer) == pd.core.frame.DataFrame)\n",
    "assert(round(answer.query(\"Medicaid_EP_Hospital_Type == 'Acute Care Hospitals'\")['Avg_Pay_per_Capita'].sum(),3) == 106.583)\n",
    "assert(round(answer.query(\"Medicaid_EP_Hospital_Type == 'Children\\\\'s Hospitals'\")['Avg_Pay_per_Capita'].sum(),3) == 329.551)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Are you ready to submit your work?\n",
      "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
      "2. Type \"yes\" or \"no\" below\n",
      "3. Press Enter\n",
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "\t\u001b[31m../EHR.csv\u001b[m\n",
      "\t\u001b[31m../HospInfo.csv\u001b[m\n",
      "\t\u001b[31m../Untitled.ipynb\u001b[m\n",
      "\t\u001b[31m../Untitled1.ipynb\u001b[m\n",
      "\t\u001b[31m../apache_patients.csv\u001b[m\n",
      "\t\u001b[31m../week 03/week03_class.ipynb\u001b[m\n",
      "\t\u001b[31m../week 04/week04_examples.ipynb\u001b[m\n",
      "\t\u001b[31m../week 04/week04_lookups.ipynb\u001b[m\n",
      "\t\u001b[31m../week 05/\u001b[m\n",
      "\t\u001b[31m../week 06/module29-xml-examples.ipynb\u001b[m\n",
      "\t\u001b[31m../week 06/week06_inclass_1.ipynb\u001b[m\n",
      "\t\u001b[31m../week 10/Number_of_Cancer_Cases_for_All_Cancer_Sites_by_Jurisdiction__Gender__and_Race__Maryland_2009.csv\u001b[m\n",
      "\t\u001b[31m../week 13/HospInfo.csv\u001b[m\n",
      "\t\u001b[31m../week02/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git pull\n",
    "    !git add week15_assignment.ipynb\n",
    "    !git commit -a -m \"Submitting the week 15 programming assignment\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
